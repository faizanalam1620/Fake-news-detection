{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueData=pd.read_csv('True.csv')\n",
    "fakeData=pd.read_csv('Fake.csv')\n",
    "print(trueData.head(),fakeData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueData['label'] = 1\n",
    "fakeData['label'] = 0\n",
    "data = pd.concat([trueData, fakeData])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization using Seaborn\n",
    "import seaborn as sbn\n",
    "sbn.set_style(\"darkgrid\")\n",
    "sbn.countplot(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "data['subject'].value_counts()\n",
    "plt.figure(figsize = (10,10))\n",
    "sbn.set_style(\"darkgrid\")\n",
    "sbn.countplot(data['subject']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sbn.set_style(\"dark\")\n",
    "chart = sbn.countplot(x = \"label\", hue = \"subject\" , data = data)\n",
    "chart.set_xticklabels(chart.get_xticklabels(),rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['text'] = data['title'] + \" \" + data['text']\n",
    "data = data.drop(['title', 'subject', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords.words('english'), \n",
    "                min_font_size = 10).generate(\" \".join(data[data['label'] == 0].text)) \n",
    "  \n",
    "# plot the word cloud for fake news data                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "print(\"wordcloud for fake or spam data\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords.words('english'), \n",
    "                min_font_size = 10).generate(\" \".join(data[data['label'] == 1].text)) \n",
    "  \n",
    "# plot the WordCloud image for genuine news data                     \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "print(\"True or fact data wordcloud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data['text'],data['label'],test_size=0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial NB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics                                                 \n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "mnbModel = pipe.fit(x_train, y_train)\n",
    "prediction = mnbModel.predict(x_test)\n",
    "\n",
    "mnbScore = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"accuracy using multinomial naive bayes:   %0.3f\" % (mnbScore*100))\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n",
    "                                show_normed=True,\n",
    "                                colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "svmModel = pipe.fit(x_train, y_train)\n",
    "prediction = svmModel.predict(x_test)\n",
    "\n",
    "svmScore = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy using Support vector machine:   %0.3f\" % (svmScore*100))\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n",
    "                                show_normed=True, colorbar=True\n",
    "                                )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passive Aggressive Classifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf',  PassiveAggressiveClassifier())\n",
    "])\n",
    "\n",
    "pacModel = pipe.fit(x_train, y_train)\n",
    "prediction = pacModel.predict(x_test)\n",
    "\n",
    "pacScore = metrics.accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy using Passive aggressive classifier:   %0.3f\" % (pacScore*100))\n",
    "cm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n",
    "                                show_normed=True,\n",
    "                                colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::::::::GLOVE:::::::::::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100000\n",
    "oov_token = \"<OOV>\"\n",
    "max_length = 100\n",
    "padding_type = \"post\"\n",
    "trunction_type=\"post\"\n",
    "print(data)\n",
    "news_text=data.text\n",
    "labels = data.label\n",
    "(train_texts,valid_texts,train_labels,valid_labels)=train_test_split(news_text, labels, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "print(X_train_sequences)\n",
    "#X_train_sequences[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences,maxlen=max_length, padding=padding_type, \n",
    "                       truncating=trunction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = tokenizer.texts_to_sequences(valid_texts)\n",
    "X_test_padded = pad_sequences(X_test_sequences,maxlen=max_length, \n",
    "                               padding=padding_type, truncating=trunction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(\"Found %s word vectors\"%len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, max_length))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            max_length,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "input_length = 100\n",
    "model = Sequential([\n",
    "  embedding_layer,\n",
    "  Bidirectional(LSTM(embedding_dim, return_sequences=True)),\n",
    "  Bidirectional(LSTM(embedding_dim,)),\n",
    "  Dense(6),\n",
    "  Dense(1)\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=3\n",
    "history = model.fit(X_train_padded, train_labels, epochs=num_epochs, validation_data=(X_test_padded, valid_labels))\n",
    "loss, accuracy = model.evaluate(X_test_padded, valid_labels)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical user interface using Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "from PIL import ImageTk,Image\n",
    "class MyWindow:\n",
    "    def __init__(self, win):\n",
    "        self.lbl1=Label(win, text='Enter the news ')\n",
    "        self.t1=Entry(bd=4)\n",
    "        self.lbl1.place(x=100, y=30)\n",
    "        self.t1.place(x=270, y=30)\n",
    "        self.b1=Button(win,bg='darkcyan',fg='white',activebackground='green' ,text='Check on SVM',command=self.svmModel)\n",
    "        self.b2=Button(win,bg='darkcyan',fg='white',activebackground='green' ,text='Check on MNB',command=self.mnbModel)\n",
    "        self.b3=Button(win,bg='darkcyan',fg='white',activebackground='green' ,text='Check on PAC',command=self.pacModel)\n",
    "        self.b4=Button(win,bg='darkcyan',fg='white',activebackground='green' ,text='Check on GLOVE',command=self.gloveModel)\n",
    "        self.b5=Button(win,bg='darkcyan',fg='white',activebackground='green', text='Positive Word Frequency', command=self.positiveWordFrequency)\n",
    "        self.b6=Button(win,bg='darkcyan',fg='white',activebackground='green', text='NegativeWord Frequency', command=self.negativeWordFrequency)\n",
    "        self.b1.place(x=100, y=90)\n",
    "        self.b2.place(x=230, y=90)\n",
    "        self.b3.place(x=360, y=90)\n",
    "        self.b4.place(x=490, y=90)\n",
    "        self.b5.place(x=640, y=90)\n",
    "        self.b6.place(x=840, y=90)\n",
    "\n",
    "\n",
    "    def svmModel(self):\n",
    "       value=self.t1.get()\n",
    "       result=svmModel.predict([value])\n",
    "       image1 = Image.open(\"true.jpeg\")\n",
    "       if(result[0]==0):\n",
    "           image1 = Image.open(\"fake.jpeg\")\n",
    "\n",
    "       image1= image1.resize((800,605), Image.ANTIALIAS)\n",
    "       test = ImageTk.PhotoImage(image1)\n",
    "       self.label1 = tkinter.Label(image=test)\n",
    "       self.label1.image = test\n",
    "       self.label1.place(x=170, y=200)\n",
    "      \n",
    "\n",
    "    def mnbModel(self):\n",
    "       value=self.t1.get()\n",
    "       result=mnbModel.predict([value])\n",
    "       image1 = Image.open(\"true.jpeg\")\n",
    "       if(result[0]==0):\n",
    "           image1 = Image.open(\"fake.jpeg\")\n",
    "\n",
    "       image1= image1.resize((800,605), Image.ANTIALIAS)\n",
    "       test = ImageTk.PhotoImage(image1)\n",
    "       label1 = tkinter.Label(image=test)\n",
    "       label1.image = test\n",
    "       label1.place(x=170, y=200)\n",
    "      \n",
    "\n",
    "    def pacModel(self):\n",
    "       value=self.t1.get()\n",
    "       result=pacModel.predict([value])\n",
    "       image1 = Image.open(\"true.jpeg\")\n",
    "       if(result[0]==0):\n",
    "           image1 = Image.open(\"fake.jpeg\")\n",
    "\n",
    "       image1= image1.resize((800,605), Image.ANTIALIAS)\n",
    "       test = ImageTk.PhotoImage(image1)\n",
    "       label1 = tkinter.Label(image=test)\n",
    "       label1.image = test\n",
    "       label1.place(x=170, y=200)\n",
    "     \n",
    "\n",
    "    def gloveModel(self):\n",
    "       value=self.t1.get()\n",
    "       valueSequence = tokenizer.texts_to_sequences([value])\n",
    "       padValue= pad_sequences(valueSequence,maxlen=max_length, \n",
    "                               padding=padding_type, truncating=trunction_type)\n",
    "       result=model.predict(padValue)\n",
    "       image1 = Image.open(\"true.jpeg\")\n",
    "       if(result[0]<0.5):\n",
    "           image1 = Image.open(\"fake.jpeg\")\n",
    "\n",
    "       image1= image1.resize((800,605), Image.ANTIALIAS)\n",
    "       test = ImageTk.PhotoImage(image1)\n",
    "       label1 = tkinter.Label(image=test)\n",
    "       label1.image = test\n",
    "       label1.place(x=170, y=200)\n",
    "  \n",
    "       \n",
    "\n",
    "    def positiveWordFrequency(self):\n",
    "        try:\n",
    "            self.canvas.get_tk_widget().pack_forget()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "       # self.textLabel1.destroy()\n",
    "        fig = Figure(figsize=(12,10))\n",
    "        a = fig.add_subplot(111)\n",
    "        \n",
    "        wordcloud = WordCloud(width = 1800, height = 1800, \n",
    "                 background_color ='white', \n",
    "                 stopwords = stopwords.words('english'), \n",
    "                 min_font_size = 10).generate(\" \".join(data[data['label'] == 1].text)) \n",
    "        a.imshow(wordcloud,interpolation='bilinear')\n",
    "        a.axis('off')\n",
    "        self.canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "        self.canvas.get_tk_widget().pack( expand=1)\n",
    "        self.canvas.draw()\n",
    "\n",
    "    def negativeWordFrequency(self):\n",
    "        try:\n",
    "            self.canvas.get_tk_widget().pack_forget()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "       # self.textLabel1.destroy()\n",
    "        fig = Figure(figsize=(10,8))\n",
    "        a = fig.add_subplot(111)\n",
    "        \n",
    "        wordcloud = WordCloud(width = 1800, height = 1800, \n",
    "                 background_color ='white', \n",
    "                 stopwords = stopwords.words('english'), \n",
    "                 min_font_size = 10).generate(\" \".join(data[data['label'] == 0].text)) \n",
    "        a.imshow(wordcloud,interpolation='bilinear')\n",
    "        a.axis('off')\n",
    "        self.canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "        self.canvas.get_tk_widget().pack( expand=1)\n",
    "        self.canvas.draw()\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window=Tk()\n",
    "mywin=MyWindow(window) \n",
    "window.title('Fake news detection system')\n",
    "window.configure(bg='skyblue')\n",
    "window.geometry(\"1200x1000+10+10\")\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 3,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
